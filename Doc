FROM nvidia/cuda:11.8.0-devel-ubuntu22.04

WORKDIR /app

# SSL bypass environment variables
ENV PYTHONHTTPSVERIFY=0
ENV CURL_CA_BUNDLE=""
ENV REQUESTS_CA_BUNDLE=""

RUN apt-get update && apt-get install -y \
    python3 \
    python3-pip \
    python3-dev \
    build-essential \
    cmake \
    git \
    && rm -rf /var/lib/apt/lists/*

RUN ln -s /usr/bin/python3 /usr/bin/python

# Configure pip SSL bypass
RUN pip config set global.trusted-host "pypi.org files.pythonhosted.org pypi.python.org download.pytorch.org"

# Install llama-cpp-python with CUDA support using CMAKE args
ENV CMAKE_ARGS="-DGGML_CUDA=on"
RUN pip install --no-cache-dir \
    --trusted-host pypi.org \
    --trusted-host files.pythonhosted.org \
    --trusted-host pypi.python.org \
    llama-cpp-python

# Install other packages
RUN pip install --no-cache-dir \
    --trusted-host pypi.org \
    --trusted-host files.pythonhosted.org \
    --trusted-host pypi.python.org \
    torch==2.1.0 \
    torchvision==0.16.0 \
    torchaudio==2.1.0 \
    --index-url https://download.pytorch.org/whl/cu118

RUN pip install --no-cache-dir \
    --trusted-host pypi.org \
    --trusted-host files.pythonhosted.org \
    --trusted-host pypi.python.org \
    sentence-transformers==2.7.0 \
    chromadb==0.4.24 \
    PyPDF2==3.0.1 \
    fastapi==0.104.1 \
    uvicorn[standard]==0.24.0 \
    transformers==4.36.0 \
    accelerate==0.25.0 \
    jinja2==3.1.2 \
    python-multipart==0.0.6

COPY scripts/ ./scripts/
COPY models/ ./models/
COPY Engine/ ./Engine/

ENV MAUROGPT2_BASE=/app
EXPOSE 8000
CMD ["python", "scripts/maurogpt2-model.py"]
