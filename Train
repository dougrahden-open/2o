# maurogpt2-training.py - PDF Processing and Embedding Training

# %% Cell 1: Imports and Dependencies

import os
import re
from pathlib import Path
from PyPDF2 import PdfReader
from sentence_transformers import SentenceTransformer
import chromadb
from chromadb.config import Settings
import shutilhttps://openai.com/index/response-to-nyt-data-demands/

# %% Cell 2: Configuration - Change base directory here for different environments

BASE_DIR = Path(“D:/aa039v2”)
MODELS_DIR = BASE_DIR / “models”
INPUTS_DIR = BASE_DIR / “inputs”
RAW_PDFS_DIR = INPUTS_DIR / “raw-pdfs”
PREPPED_PDFS_DIR = INPUTS_DIR / “prepped-pdfs”
ENGINE_DIR = BASE_DIR / “Engine”

# Model paths

BGE_MODEL_PATH = MODELS_DIR / “bge-large-en-v15”
COLLECTION_NAME = “pdf_collection”

# %% Cell 3: Directory Setup Functions

def setup_directories():
“”“Create all necessary directories if they don’t exist”””
for directory in [INPUTS_DIR, RAW_PDFS_DIR, PREPPED_PDFS_DIR, ENGINE_DIR]:
directory.mkdir(parents=True, exist_ok=True)
print(f”Directories set up in: {BASE_DIR}”)

# %% Cell 4: PDF Selection Logic with Version Control

def get_latest_pdfs():
“””
Get the latest version of each PDF based on:
1. Suffix priority: _A -> _B -> _C -> _D -> _0 -> _1 -> _2 -> etc.
2. File modification date (newest wins)
“””
pdf_groups = {}

```
# Group PDFs by base name
for pdf_file in RAW_PDFS_DIR.glob("*.pdf"):
    filename = pdf_file.stem
    mod_time = pdf_file.stat().st_mtime
    
    # Extract base name and suffix
    if re.match(r'.*_[A-Z]$', filename):
        # Ends with single letter (A, B, C, etc.)
        base_name = filename[:-2]
        suffix_char = filename[-1]
        suffix = ord(suffix_char) - ord('A')  # A=0, B=1, C=2, etc.
        suffix_type = 'letter'
    elif re.match(r'.*_\d+$', filename):
        # Ends with _number
        parts = filename.rsplit('_', 1)
        base_name = parts[0]
        suffix = int(parts[1])
        suffix_type = 'number'
    else:
        # No suffix, treat as base version
        base_name = filename
        suffix = -1
        suffix_type = 'base'
        
    if base_name not in pdf_groups:
        pdf_groups[base_name] = []
    pdf_groups[base_name].append((suffix_type, suffix, mod_time, pdf_file))

# Select latest version for each base name
latest_pdfs = []
for base_name, versions in pdf_groups.items():
    # Sort by priority: 
    # 1. numbers (highest first) 
    # 2. letters (highest first: Z, Y, X, ..., C, B, A)
    # 3. base version (lowest priority)
    # 4. modification time (newest first) as tiebreaker
    def sort_key(item):
        suffix_type, suffix, mod_time, file_path = item
        if suffix_type == 'number':
            return (2, suffix, mod_time)  # Numbers highest priority
        elif suffix_type == 'letter':
            return (1, suffix, mod_time)  # Letters second priority
        else:
            return (0, suffix, mod_time)  # Base version lowest priority
            
    sorted_versions = sorted(versions, key=sort_key, reverse=True)
    latest_file = sorted_versions[0][3]  # Get file path
    latest_suffix = sorted_versions[0][1]
    latest_type = sorted_versions[0][0]
    
    # Create readable suffix description
    if latest_type == 'number':
        suffix_desc = f"_{latest_suffix}"
    elif latest_type == 'letter':
        suffix_desc = f"_{chr(latest_suffix + ord('A'))}"
    else:
        suffix_desc = "(base)"
        
    latest_pdfs.append(latest_file)
    print(f"Selected: {latest_file.name} {suffix_desc} (from {len(versions)} versions)")

return latest_pdfs
```

# %% Cell 5: PDF Preparation and Update Detection

def prepare_pdfs():
“”“Copy latest PDFs to prepped directory, only if updates are needed”””
latest_pdfs = get_latest_pdfs()

```
if not latest_pdfs:
    print("No PDFs found in raw directory!")
    return []

# Check if prepped directory exists and has files
existing_prepped = []
if PREPPED_PDFS_DIR.exists():
    existing_prepped = list(PREPPED_PDFS_DIR.glob("*.pdf"))

# Determine if we need to update
needs_update = False

if len(existing_prepped) != len(latest_pdfs):
    needs_update = True
    print(f"File count changed: {len(existing_prepped)} -> {len(latest_pdfs)}")
else:
    # Check if any files are different or newer
    existing_names = {f.name for f in existing_prepped}
    latest_names = {f.name for f in latest_pdfs}
    
    if existing_names != latest_names:
        needs_update = True
        print("Different files selected")
    else:
        # Check modification times
        for latest_pdf in latest_pdfs:
            prepped_file = PREPPED_PDFS_DIR / latest_pdf.name
            if prepped_file.exists():
                latest_mod_time = latest_pdf.stat().st_mtime
                prepped_mod_time = prepped_file.stat().st_mtime
                if latest_mod_time > prepped_mod_time:
                    needs_update = True
                    print(f"Newer version detected: {latest_pdf.name}")
                    break
            else:
                needs_update = True
                print(f"Missing file: {latest_pdf.name}")
                break

if not needs_update:
    print("No updates needed - all files are current")
    return latest_pdfs

# Clear prepped directory and copy fresh files
if PREPPED_PDFS_DIR.exists():
    shutil.rmtree(PREPPED_PDFS_DIR)
PREPPED_PDFS_DIR.mkdir(parents=True, exist_ok=True)

for pdf_file in latest_pdfs:
    dest_path = PREPPED_PDFS_DIR / pdf_file.name
    shutil.copy2(pdf_file, dest_path)  # copy2 preserves metadata
    print(f"Copied: {pdf_file.name}")

print(f"Prepared {len(latest_pdfs)} PDFs in {PREPPED_PDFS_DIR}")
return latest_pdfs
```

# %% Cell 6: Model and Database Initialization

def setup_models():
“”“Initialize ChromaDB and load BGE embedding model”””
# Initialize ChromaDB
chroma_client = chromadb.PersistentClient(path=str(ENGINE_DIR))

```
# Delete existing collection and create fresh one
try:
    chroma_client.delete_collection(COLLECTION_NAME)
    print(f"Deleted existing collection: {COLLECTION_NAME}")
except Exception as e:
    print(f"No existing collection to delete: {e}")

collection = chroma_client.create_collection(name=COLLECTION_NAME)
print(f"Created fresh collection: {COLLECTION_NAME}")

# Load BGE embedding model
print(f"Loading BGE model from: {BGE_MODEL_PATH}")
embedding_model = SentenceTransformer(str(BGE_MODEL_PATH), device='cuda')
print(f"BGE model loaded on device: {embedding_model.device}")

return collection, embedding_model
```

# %% Cell 7: PDF Text Extraction Functions

def extract_text_from_pdf(pdf_path):
“”“Extract text from PDF and split into chunks”””
try:
reader = PdfReader(pdf_path)
chunks = []

```
    for page_num, page in enumerate(reader.pages, 1):
        text = page.extract_text()
        
        if text.strip():
            # Split page into smaller chunks (roughly 512 tokens each)
            words = text.split()
            chunk_size = 400  # words per chunk
            
            for i in range(0, len(words), chunk_size):
                chunk_words = words[i:i + chunk_size]
                chunk_text = ' '.join(chunk_words)
                
                if len(chunk_text.strip()) > 50:  # Skip very short chunks
                    chunks.append({
                        'text': chunk_text,
                        'source_pdf': pdf_path.name,
                        'page_number': page_num,
                        'chunk_index': i // chunk_size
                    })
    
    return chunks

except Exception as e:
    print(f"Error processing {pdf_path.name}: {e}")
    return []
```

# %% Cell 8: Embedding Generation and Storage

def embed_and_store_pdfs(collection, embedding_model):
“”“Process all prepped PDFs and store embeddings”””
all_chunks = []

```
# Extract text from all PDFs
for pdf_file in PREPPED_PDFS_DIR.glob("*.pdf"):
    print(f"Processing: {pdf_file.name}")
    chunks = extract_text_from_pdf(pdf_file)
    all_chunks.extend(chunks)
    print(f"  Extracted {len(chunks)} chunks")

if not all_chunks:
    print("No chunks to embed!")
    return

print(f"Total chunks to embed: {len(all_chunks)}")

# Generate embeddings
texts = [chunk['text'] for chunk in all_chunks]
print("Generating embeddings...")
embeddings = embedding_model.encode(texts, show_progress_bar=True)

# Prepare data for ChromaDB
documents = texts
metadatas = [{
    'source_pdf': chunk['source_pdf'],
    'page_number': chunk['page_number'],
    'chunk_index': chunk['chunk_index']
} for chunk in all_chunks]
ids = [f"{chunk['source_pdf']}_{chunk['page_number']}_{chunk['chunk_index']}" 
       for chunk in all_chunks]

# Store in ChromaDB
print("Storing embeddings in ChromaDB...")
collection.add(
    documents=documents,
    embeddings=embeddings.tolist(),
    metadatas=metadatas,
    ids=ids
)

print(f"Successfully stored {len(all_chunks)} embeddings!")
```

# %% Cell 9: Main Execution Pipeline

def main():
print(”=== MauroGPT2 Training Pipeline ===”)

```
# Setup
setup_directories()

# Prepare PDFs (check for updates)
print("\n1. Checking for PDF updates...")
latest_pdfs = prepare_pdfs()

if not latest_pdfs:
    print("No PDFs found to process!")
    return

# Check if we actually need to rebuild embeddings
if PREPPED_PDFS_DIR.exists():
    existing_prepped = list(PREPPED_PDFS_DIR.glob("*.pdf"))
    if len(existing_prepped) == len(latest_pdfs):
        # Check if ChromaDB exists and has data
        try:
            chroma_client = chromadb.PersistentClient(path=str(ENGINE_DIR))
            collection = chroma_client.get_collection(COLLECTION_NAME)
            if collection.count() > 0:
                print(f"Database already exists with {collection.count()} embeddings")
                print("Run with --force to rebuild database")
                return
        except:
            pass  # Database doesn't exist, continue with creation

# Setup models
print("\n2. Setting up models and database...")
collection, embedding_model = setup_models()

# Process PDFs
print("\n3. Processing PDFs and generating embeddings...")
embed_and_store_pdfs(collection, embedding_model)

print("\n=== Training Complete! ===")
print(f"Database location: {ENGINE_DIR}")
print(f"Total documents in collection: {collection.count()}")
```

if **name** == “**main**”:
main()
