# maurogpt2-training.py - PDF Processing and Embedding Training

# %% Cell 1: Imports and Dependencies

import os
import re
from pathlib import Path
from PyPDF2 import PdfReader
from sentence_transformers import SentenceTransformer
import chromadb
from chromadb.config import Settings
import shutil
import torch
import gc
from datetime import datetime

# %% Cell 2: Configuration - Base Paths and A6000/A40 Optimized Settings
# Change base directory here for different environments
BASE_DIR = Path("D:/aa039v2")
MODELS_DIR = BASE_DIR / "models"
INPUTS_DIR = BASE_DIR / "inputs"
RAW_PDFS_DIR = INPUTS_DIR / "raw-pdfs"
PREPPED_PDFS_DIR = INPUTS_DIR / "prepped-pdfs"
ENGINE_DIR = BASE_DIR / "Engine"

# Model and collection config
BGE_MODEL_PATH = MODELS_DIR / "bge-large-en-v15"
COLLECTION_NAME = "pdf_collection"

# === A6000 / A40 Optimized Settings ===
EMBEDDING_BATCH_SIZE = 256       # Very high batch for 48GB VRAM
STORAGE_BATCH_SIZE = 2000        # Batch DB writes to avoid memory spikes
CHUNK_SIZE = 400                 # Number of words per chunk
USE_FP16 = True                  # Use half precision for faster GPU inference

# %% Cell 3: Directory Setup Functions

def setup_directories():
    """Create all necessary directories if they don’t exist"""
    directories = [INPUTS_DIR, RAW_PDFS_DIR, PREPPED_PDFS_DIR, ENGINE_DIR]
    for directory in directories:
        directory.mkdir(parents=True, exist_ok=True)
    print(f"Directories set up in: {BASE_DIR}")
    
    for dir_name, dir_path in [
        ("Raw PDFs", RAW_PDFS_DIR),
        ("Prepped PDFs", PREPPED_PDFS_DIR),
        ("ChromaDB", ENGINE_DIR)
    ]:
        if dir_path.exists():
            file_count = len(list(dir_path.glob("*")))
            print(f"  {dir_name}: {file_count} files")

# %% Cell 4: PDF Selection Logic with Version Control

def get_latest_pdfs():
    """Get the latest version of each PDF"""
    print("Scanning for PDFs...")
    pdf_groups = {}

    for pdf_file in RAW_PDFS_DIR.glob("*.pdf"):
        filename = pdf_file.stem
        mod_time = pdf_file.stat().st_mtime
        
        if re.match(r".*_[A-Z]$", filename):
            base_name = filename[:-2]
            suffix = ord(filename[-1]) - ord("A")
            suffix_type = "letter"
        elif re.match(r".*_\d+$", filename):
            parts = filename.rsplit("_", 1)
            base_name = parts[0]
            suffix = int(parts[1])
            suffix_type = "number"
        else:
            base_name = filename
            suffix = -1
            suffix_type = "base"
        
        pdf_groups.setdefault(base_name, []).append((suffix_type, suffix, mod_time, pdf_file))

    if not pdf_groups:
        print(f"No PDFs found in {RAW_PDFS_DIR}")
        return []

    latest_pdfs = []
    for base_name, versions in pdf_groups.items():
        def sort_key(item):
            suffix_type, suffix, mod_time, _ = item
            if suffix_type == "number":
                return (2, suffix, mod_time)
            elif suffix_type == "letter":
                return (1, suffix, mod_time)
            else:
                return (0, suffix, mod_time)

        sorted_versions = sorted(versions, key=sort_key, reverse=True)
        latest_file = sorted_versions[0][3]
        latest_type = sorted_versions[0][0]
        latest_suffix = sorted_versions[0][1]

        if latest_type == "number":
            suffix_desc = f"_{latest_suffix}"
        elif latest_type == "letter":
            suffix_desc = f"_{chr(latest_suffix + ord('A'))}"
        else:
            suffix_desc = "(base)"

        latest_pdfs.append(latest_file)
        print(f"Selected: {latest_file.name} {suffix_desc} (from {len(versions)} versions)")

    return latest_pdfs

# %% Cell 5: PDF Preparation and Update Detection

def get_latest_pdfs():
    """Get the latest version of each PDF based on suffix + mod time"""
    print("Scanning for PDFs...")
    pdf_groups = {}

    for pdf_file in RAW_PDFS_DIR.glob("*.pdf"):
        filename = pdf_file.stem
        mod_time = pdf_file.stat().st_mtime
        
        if re.match(r".*_[A-Z]$", filename):
            base_name = filename[:-2]
            suffix = ord(filename[-1]) - ord("A")
            suffix_type = "letter"
        elif re.match(r".*_\d+$", filename):
            parts = filename.rsplit("_", 1)
            base_name = parts[0]
            suffix = int(parts[1])
            suffix_type = "number"
        else:
            base_name = filename
            suffix = -1
            suffix_type = "base"
        
        pdf_groups.setdefault(base_name, []).append((suffix_type, suffix, mod_time, pdf_file))

    if not pdf_groups:
        print(f"No PDFs found in {RAW_PDFS_DIR}")
        return []

    total_files = sum(len(v) for v in pdf_groups.values())
    print(f"Found {total_files} total PDF files across {len(pdf_groups)} base documents")

    latest_pdfs = []
    for base_name, versions in pdf_groups.items():
        def sort_key(item):
            suffix_type, suffix, mod_time, _ = item
            if suffix_type == "number":
                return (2, suffix, mod_time)
            elif suffix_type == "letter":
                return (1, suffix, mod_time)
            else:
                return (0, suffix, mod_time)

        sorted_versions = sorted(versions, key=sort_key, reverse=True)
        latest_file = sorted_versions[0][3]
        latest_type = sorted_versions[0][0]
        latest_suffix = sorted_versions[0][1]

        suffix_desc = (
            f"_{latest_suffix}" if latest_type == "number" else
            f"_{chr(latest_suffix + ord('A'))}" if latest_type == "letter" else
            "(base)"
        )

        latest_pdfs.append(latest_file)
        skipped = sorted_versions[1:]
        print(f"Selected: {latest_file.name} {suffix_desc} (skipped {len(skipped)} other versions)")
        for _, _, _, skipped_file in skipped:
            print(f"  - Skipped: {skipped_file.name}")

    return latest_pdfs


def prepare_pdfs():
    """Copy latest PDFs to prepped directory, only if updates are needed"""
    latest_pdfs = get_latest_pdfs()
    if not latest_pdfs:
        print("No PDFs found in raw directory!")
        return []

    print(f"\nFinal selection: {len(latest_pdfs)} unique PDFs will be used for embedding.")

    existing_prepped = list(PREPPED_PDFS_DIR.glob("*.pdf")) if PREPPED_PDFS_DIR.exists() else []

    needs_update = False

    if len(existing_prepped) != len(latest_pdfs):
        needs_update = True
        print(f"Prepped directory file count changed: {len(existing_prepped)} → {len(latest_pdfs)}")
    else:
        existing_names = {f.name for f in existing_prepped}
        latest_names = {f.name for f in latest_pdfs}
        
        if existing_names != latest_names:
            needs_update = True
            print("Prepped directory file names differ from selected latest PDFs")
        else:
            for latest_pdf in latest_pdfs:
                prepped_file = PREPPED_PDFS_DIR / latest_pdf.name
                if not prepped_file.exists() or latest_pdf.stat().st_mtime > prepped_file.stat().st_mtime:
                    needs_update = True
                    print(f"Newer or missing file detected: {latest_pdf.name}")
                    break

    if not needs_update:
        print("No updates needed — all PDFs already prepped and current.")
        return latest_pdfs

    if PREPPED_PDFS_DIR.exists():
        shutil.rmtree(PREPPED_PDFS_DIR)
    PREPPED_PDFS_DIR.mkdir(parents=True, exist_ok=True)

    print(f"\nCopying {len(latest_pdfs)} selected PDFs to prepped-pdfs...")
    for pdf_file in latest_pdfs:
        dest_path = PREPPED_PDFS_DIR / pdf_file.name
        shutil.copy2(pdf_file, dest_path)
        print(f"  Copied: {pdf_file.name}")

    print(f"Prepared {len(latest_pdfs)} PDFs in {PREPPED_PDFS_DIR}")
    return latest_pdfs

# %% Cell 6: Model and Database Initialization (FP16-safe)

from sentence_transformers import SentenceTransformer

def setup_models():
    """Initialize ChromaDB and load BGE embedding model with A6000 optimizations"""
    print("Setting up models and database...")

    if torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name(0)
        vram = torch.cuda.get_device_properties(0).total_memory / 1e9
        print(f"GPU: {gpu_name} ({vram:.1f} GB)")
        print(f"Using FP16: {USE_FP16}")
        print(f"Embedding Batch Size: {EMBEDDING_BATCH_SIZE}")
    else:
        print("WARNING: CUDA not available — using CPU")

    chroma_client = chromadb.PersistentClient(path=str(ENGINE_DIR))
    try:
        chroma_client.delete_collection(COLLECTION_NAME)
        print(f"Deleted existing collection: {COLLECTION_NAME}")
    except:
        print("No existing collection to delete")

    collection = chroma_client.create_collection(name=COLLECTION_NAME)

    # Load model
    print(f"Loading embedding model from: {BGE_MODEL_PATH}")
    embedding_model = SentenceTransformer(
        str(BGE_MODEL_PATH),
        device='cuda' if torch.cuda.is_available() else 'cpu'
    )

    # Cast model to half precision if on GPU
    if USE_FP16 and torch.cuda.is_available():
        embedding_model._target_device = torch.device("cuda")
        embedding_model.model = embedding_model.model.half()
        print("Model cast to FP16")

    print("Warming up model...")
    _ = embedding_model.encode(["Warm-up embedding"])
    print("Model ready.")

    return collection, embedding_model

# %% Cell 7: PDF Text Extraction Functions

def extract_text_from_pdf(pdf_path):
    """Extract text from PDF and split into optimized chunks"""
    try:
        reader = PdfReader(pdf_path)
        chunks = []
        for page_num, page in enumerate(reader.pages, 1):
            text = page.extract_text()
            if text and text.strip():
                words = text.split()
                for i in range(0, len(words), CHUNK_SIZE):
                    chunk_words = words[i:i + CHUNK_SIZE]
                    chunk_text = " ".join(chunk_words)
                    if len(chunk_text.strip()) > 50:
                        chunks.append({
                            "text": chunk_text,
                            "source_pdf": pdf_path.name,
                            "page_number": page_num,
                            "chunk_index": i // CHUNK_SIZE,
                            "word_count": len(chunk_words)
                        })
        return chunks
    except Exception as e:
        print(f"Error processing {pdf_path.name}: {e}")
        return []

# %% Cell 8: Embedding Generation and Storage

def embed_and_store_pdfs(collection, embedding_model):
    """Process all prepped PDFs and store embeddings"""
    print("Processing PDFs and generating embeddings...")
    all_chunks = []

    pdf_files = list(PREPPED_PDFS_DIR.glob("*.pdf"))
    for i, pdf_file in enumerate(pdf_files, 1):
        print(f"Processing ({i}/{len(pdf_files)}): {pdf_file.name}")
        chunks = extract_text_from_pdf(pdf_file)
        all_chunks.extend(chunks)

    if not all_chunks:
        print("No chunks to embed!")
        return

    texts = [chunk["text"] for chunk in all_chunks]

    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        gc.collect()

    start_time = datetime.now()
    embeddings = embedding_model.encode(
        texts,
        show_progress_bar=True,
        batch_size=EMBEDDING_BATCH_SIZE,
        convert_to_tensor=True,
        normalize_embeddings=True,
        device="cuda" if torch.cuda.is_available() else "cpu"
    )
    embedding_time = datetime.now() - start_time

    if torch.cuda.is_available():
        embeddings = embeddings.cpu().numpy()

    print(f"Generated embeddings: {embeddings.shape} in {embedding_time}")

    documents = texts
    metadatas = [{
        "source_pdf": c["source_pdf"],
        "page_number": c["page_number"],
        "chunk_index": c["chunk_index"],
        "word_count": c["word_count"]
    } for c in all_chunks]
    ids = [f"{c['source_pdf']}_{c['page_number']}_{c['chunk_index']}" for c in all_chunks]

    num_batches = (len(all_chunks) + STORAGE_BATCH_SIZE - 1) // STORAGE_BATCH_SIZE

    for i in range(0, len(all_chunks), STORAGE_BATCH_SIZE):
        end_idx = min(i + STORAGE_BATCH_SIZE, len(all_chunks))
        collection.add(
            documents=documents[i:end_idx],
            embeddings=embeddings[i:end_idx].tolist(),
            metadatas=metadatas[i:end_idx],
            ids=ids[i:end_idx]
        )
        print(f"Stored batch {(i // STORAGE_BATCH_SIZE) + 1}/{num_batches}")

    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        gc.collect()

# %% Cell 9: Main Execution Pipeline

def main():
    """Main execution pipeline"""
    start_time = datetime.now()
    print("=" * 60)
    print("MAUROGPT2 TRAINING PIPELINE")
    print("=" * 60)
    print(f"Started: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"Base Directory: {BASE_DIR}")
    print(f"BGE Model: {BGE_MODEL_PATH}")
    print()

    try:
        print("DIRECTORY SETUP")
        setup_directories()
        print()

        print("PDF PREPARATION")
        latest_pdfs = prepare_pdfs()
        if not latest_pdfs:
            print("No PDFs found to process.")
            return
        print()

        rebuild_needed = True
        if PREPPED_PDFS_DIR.exists():
            try:
                chroma_client = chromadb.PersistentClient(path=str(ENGINE_DIR))
                collection = chroma_client.get_collection(COLLECTION_NAME)
                if collection.count() > 0:
                    print(f"Database already exists with {collection.count()} embeddings")
                    rebuild_needed = False
            except:
                pass

        if rebuild_needed:
            print("MODEL INITIALIZATION")
            collection, embedding_model = setup_models()
            print()

            print("EMBEDDING GENERATION")
            embed_and_store_pdfs(collection, embedding_model)
            print()

        end_time = datetime.now()
        duration = end_time - start_time
        print("=" * 60)
        print("TRAINING COMPLETE")
        print("=" * 60)
        print(f"Finished: {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"Duration: {duration}")
        print(f"Database location: {ENGINE_DIR}")

    except KeyboardInterrupt:
        print("\nTraining interrupted by user")
    except Exception as e:
        print(f"\nTraining failed with error: {e}")
        raise

if __name__ == "__main__":
    main()
